{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import config\n",
    "import dnnlib\n",
    "import gzip\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks for Microsoft Cognitive Services API (free trial) for labeling of generated images\n",
    "# https://azure.microsoft.com/en-us/services/cognitive-services/face/\n",
    "\n",
    "# A pretty simple logic was used for generating images:\n",
    "\n",
    "# qlatents = np.random.normal(size=(1, 512))\n",
    "# dlatents = Gs_network.components.mapping.run(qlatents, None, minibatch_size=1, randomize_noise=False, structure='fixed') # untruncated by default, I guess\n",
    "# images = Gs_network.components.synthesis.run(dlatents, minibatch_size=1, randomize_noise=False, output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), structure='fixed')\n",
    "\n",
    "# After that generated image was sent to Micriosft API and response was stored as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LATENT_TRAINING_DATA = 'https://drive.google.com/uc?id=1xMM3AFq0r014IIhBLiMCjKJJvbhLUQ9t'\n",
    "    \n",
    "with dnnlib.util.open_url(LATENT_TRAINING_DATA, cache_dir=config.cache_dir) as f:\n",
    "    qlatent_data, dlatent_data, labels_data = pickle.load(gzip.GzipFile(fileobj=f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20307, 18, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlatent_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20307"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's play with age and gender\n",
    "# you can train your own model now\n",
    "\n",
    "X_data = dlatent_data.reshape((-1, 18*512))\n",
    "facemakeup_data = np.array([x['faceAttributes']['makeup']['lipMakeup'] for x in labels_data])\n",
    "eyemakeup_data = np.array([x['faceAttributes']['makeup']['eyeMakeup']  for x in labels_data])\n",
    "\n",
    "assert(len(X_data) == len(facemakeup_data) == len(eyemakeup_data))\n",
    "len(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8672"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(facemakeup_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "batches = []\n",
    "for i in range(73):\n",
    "    batch = np.load('batch_%s.npy' % i, allow_pickle=True)\n",
    "    batches.append(batch)\n",
    "print(len(batches))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlatent_list = []\n",
    "results_list = []\n",
    "for batch in batches:\n",
    "    for example in batch:\n",
    "        dlatent_list.append(example[1])\n",
    "        results_list.append(example[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9216, 18, 512)\n",
      "(9216, 40)\n"
     ]
    }
   ],
   "source": [
    "dlatent_data = np.array(dlatent_list)\n",
    "results_data = np.array(results_list)\n",
    "print(dlatent_data.shape)\n",
    "print(results_data.shape)\n",
    "np.save('training_data_dlatents.npy', dlatent_data, allow_pickle=True)\n",
    "np.save('training_data_results.npy', results_data, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "8820.768091931703\n",
      "9216.0\n",
      "1.7889897745785747e-242\n",
      "0.0\n",
      "1.9500651130604682e-108\n",
      "0.0\n",
      "4.755820368253511e-130\n",
      "2.718067673927657e-167\n",
      "0.0\n",
      "0.0\n",
      "128.27142208156482\n",
      "2.267239740559995e-234\n",
      "9216.0\n",
      "5.7343548249991805e-297\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "9216.0\n",
      "2.0915947322176146e-79\n",
      "1.0286830792131658e-160\n",
      "2944.0452189045614\n",
      "0.0\n",
      "0.0\n",
      "9216.0\n",
      "9216.0\n",
      "0.0\n",
      "0.0\n",
      "2.2839488881564857e-175\n",
      "6.874424945282605e-22\n",
      "6.255714506286783e-246\n",
      "400.6844268437197\n",
      "1.4383541357529462e-183\n",
      "9216.0\n",
      "127.9999939599657\n",
      "0.0\n",
      "9216.0\n",
      "0.0\n",
      "0.0\n",
      "9216.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import logistic\n",
    "for i in range(40):\n",
    "    print(np.sum(logistic.cdf(results_data[:, i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a linear model for obtaining gender direction in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 6s, sys: 2.16 s, total: 2min 8s\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "facemakeup_classifier = LogisticRegression(class_weight='balanced').fit(X_data, facemakeup_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['facemakeup_classifier.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facemakeup_direction = facemakeup_classifier.coef_.reshape((18, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('facemakeup_direction.npy', facemakeup_direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6609218  0.75219147]\n",
      "Mean:  0.7065566373582086\n",
      "CPU times: user 2min 41s, sys: 2.69 s, total: 2min 43s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = SGDClassifier('log', class_weight='balanced') # SGB model for performance sake\n",
    "scores = cross_val_score(clf, X_data, facemakeup_data, scoring='accuracy', cv=2)\n",
    "clf.fit(X_data, facemakeup_data)\n",
    "\n",
    "print(scores)\n",
    "print('Mean: ', np.mean(scores))\n",
    "\n",
    "# Accuracy ? Meh. But gender distribution is almost balanced ... at least for simplicity sake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = facemakeup_data\n",
    "y_test = facemakeup_classifier.predict(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"PR curve for 'heavy makeup' linear classifier. AP=0.73\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from inspect import signature\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "\n",
    "\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.1,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.1, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('PR curve for \\'heavy makeup\\' linear classifier. AP={0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependency of gender detection errors on age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, bin_edges = np.histogram(y_age_data, bins=30)\n",
    "errors,_ = np.histogram(y_age_data[clf.predict(X_data) != y_gender_data], bin_edges)\n",
    "\n",
    "plt.plot(errors / bins)\n",
    "plt.title('Dependency of gender detection errors on age')\n",
    "plt.ylabel('Gender detection error rate')\n",
    "plt.xlabel('Age')\n",
    "plt.show()\n",
    "\n",
    "# Seems that the most diffictul for model is to distinguish babies. For me as well to be honest.\n",
    "# Or model which we used for creating \"ground truth\" produces random guesses\n",
    "# I bet that both are true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependency of accuracy on training data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "nb_folds = 5\n",
    "splits = 20\n",
    "scores = np.zeros((splits, nb_folds))\n",
    "dataset_size = list()\n",
    "\n",
    "for fold_id, (train_idx, test_idx) in enumerate(StratifiedKFold(nb_folds, True, 42).split(X_data, y_gender_data)):\n",
    "    X_train, X_test = X_data[train_idx][:1000], X_data[test_idx]\n",
    "    y_train, y_test = y_gender_data[train_idx][:1000], y_gender_data[test_idx]\n",
    "    \n",
    "    for split_id in range(splits):\n",
    "        nb_samples = int((len(X_train)/splits) * (split_id+1))\n",
    "        dataset_size.append(nb_samples)\n",
    "        clf = SGDClassifier('log', class_weight='balanced').fit(X_train[:nb_samples], y_train[:nb_samples])\n",
    "        scores[split_id][fold_id] = accuracy_score(y_test, clf.predict(X_test))\n",
    "        \n",
    "\n",
    "plt.plot(dataset_size[:splits], scores.mean(axis=1))\n",
    "plt.title('Dependency of accuracy on training data size')\n",
    "plt.xlabel('Dataset size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Seems that 100 labeled examples is already enough to reach 80% accuracy (for gender).\n",
    "# That's an interesting insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent layers importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to find out which latent layer is most useful for predicting gender\n",
    "\n",
    "scores = list()\n",
    "for layer in tqdm_notebook(range(18)):\n",
    "    clf = SGDClassifier('log', class_weight='balanced')\n",
    "    scores.append(cross_val_score(clf, X_data.reshape((-1, 18, 512))[:,layer], y_gender_data, scoring='accuracy', cv=5).mean())\n",
    "    \n",
    "plt.plot(np.arange(0,18), scores)\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Huh? Seems that every latent layer contains some information about gender.\n",
    "# I didn't expect that to be honest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of gender transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Do you remember gender_direction ? \n",
    "# Anyway let's train it one more time\n",
    "\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "clf.fit(X_data.reshape((-1, 18*512)), y_gender_data)\n",
    "gender_dircetion = clf.coef_.reshape((18, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import dnnlib.tflib as tflib\n",
    "from encoder.generator_model import Generator\n",
    "\n",
    "URL_FFHQ = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ'\n",
    "\n",
    "tflib.init_tf()\n",
    "with dnnlib.util.open_url(URL_FFHQ, cache_dir=config.cache_dir) as f:\n",
    "    generator_network, discriminator_network, Gs_network = pickle.load(f)\n",
    "\n",
    "generator = Generator(Gs_network, batch_size=1, randomize_noise=False)\n",
    "\n",
    "def generate_image(latent_vector):\n",
    "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
    "    generator.set_dlatents(latent_vector)\n",
    "    img_array = generator.generate_images()[0]\n",
    "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
    "    return img.resize((256, 256))\n",
    "\n",
    "def move_and_show(latent_vector, direction, coeffs):\n",
    "    fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
    "    for i, coeff in enumerate(coeffs):\n",
    "        new_latent_vector = latent_vector.copy()\n",
    "        new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
    "        ax[i].imshow(generate_image(new_latent_vector))\n",
    "        ax[i].set_title('Coeff: %0.1f' % coeff)\n",
    "    [x.axis('off') for x in ax]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For generating these face untruncated sampling was used\n",
    "\n",
    "for i in range(10):\n",
    "    move_and_show(X_data.reshape((-1, 18, 512))[i], gender_dircetion, [-5, -1.5, 0, 1.5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donald_trump = np.load('ffhq_dataset/latent_representations/donald_trump_01.npy')\n",
    "move_and_show(donald_trump, gender_dircetion, [-5, -1.5, 0, 1.5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Better approach for learning better representations is coming...some regularization magic is happening\n",
    "#\n",
    "# donald_trump = np.load('dark/deep/fantasy')\n",
    "# move_and_show(donald_trump, gender_dircetion, [-5, -1.5, 0, 1.5, 5])\n",
    "\n",
    "# - here is some images -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to use some non-linear model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Maybe we can do better if we train some non-linear model ?\n",
    "But how we can move our latent vetors in non-linear space ? \n",
    "So let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_data.reshape((-1, 18*512)), y_gender_data, validation_split=0.2, epochs=5)\n",
    "model = Model(model.input, model.layers[-2].output)\n",
    "\n",
    "# works bit better, but in general accuracy is quite similar to the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some dark magic is happening here\n",
    "\n",
    "embedding_model = Sequential()\n",
    "embedding_model.add(Embedding(10, 18*512, input_length=1)) # it's actually just a variable\n",
    "embedding_model.add(Flatten())\n",
    "\n",
    "nonliner_gender_model = Model(embedding_model.input, model(embedding_model.output))\n",
    "nonliner_gender_model.layers[-1].trainable = False # fix non-linear model and train only embeddings\n",
    "nonliner_gender_model.compile('sgd', 'mse')\n",
    "\n",
    "nonliner_gender_model.layers[1].set_weights([X_data[:10].reshape((-1, 18*512))])\n",
    "y_data_real = nonliner_gender_model.predict(np.arange(10))\n",
    "y_data_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# and here\n",
    "\n",
    "nonliner_gender_model.fit(np.arange(10), np.full((10, 1), 20), verbose=0, epochs=500)\n",
    "nonliner_gender_model.predict(np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in embedding_model.layers[0].get_weights()[0]:\n",
    "    plt.imshow(generate_image(v))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reset latents and try it over but now in another direction \n",
    "nonliner_gender_model.layers[1].set_weights([X_data[:10].reshape((-1, 18*512))])\n",
    "\n",
    "nonliner_gender_model.fit(np.arange(10), np.full((10, 1), -20), verbose=0, epochs=500)\n",
    "\n",
    "for v in embedding_model.layers[0].get_weights()[0]:\n",
    "    plt.imshow(generate_image(v))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did you expect that it's gonna work ? :)\n",
    "\n",
    "# In general:\n",
    "# 1) Instead of linear model we trained a non-linear model (two layers neural network) for predicting age\n",
    "# 2) For a given latent vector we want to find a direction in non-linear space to become more male\\female\n",
    "# 3) Direction ? Sounds like we can use gradient descent...\n",
    "# 4) So that's actually what we do, step by step we optimize latent vector to become more male\\female"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
